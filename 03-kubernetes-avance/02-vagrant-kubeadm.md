# ğŸ› ï¸ TP - Mise en place d'un environnement Kubernetes pour la certification CKA

## ğŸ¯ Objectifs

- **Installer un cluster Kubernetes local** adaptÃ© Ã  la prÃ©paration de la
  certification CKA.
- **Utiliser Vagrant, Libvirt et Ansible** pour automatiser le dÃ©ploiement des
  machines virtuelles.
- **Configurer un cluster Kubernetes** avec un ou plusieurs nÅ“ud master et un ou
  plusieurs nÅ“ud worker.

## ğŸ“˜ Introduction

La certification **Certified Kubernetes Administrator (CKA)** atteste des
compÃ©tences dans la gestion de clusters Kubernetes. Pour s'y prÃ©parer
efficacement, il est essentiel de disposer d'un environnement d'apprentissage
flexible et proche des conditions de l'examen. Ce TP rÃ©pond Ã  ce besoin en
permettant de provisionner rapidement des clusters Kubernetes Ã  l'aide de
**Vagrant**, **Libvirt** et **Ansible**.

## ğŸ—ï¸ Ã‰tape 1 - PrÃ©requis

Avant de commencer, assurez-vous de disposer des Ã©lÃ©ments suivants :

1. **Une machine hÃ´te** avec au minimum **8 cÅ“urs** et **8 Go de RAM** (plus est
   recommandÃ©).
2. **SystÃ¨mes d'exploitation supportÃ©s** : Linux ou WSL.
3. **Outils installÃ©s** :
   - [Vagrant](https://blog.stephane-robert.info/docs/infra-as-code/provisionnement/vagrant/introduction/)
   - [Libvirt](https://blog.stephane-robert.info/docs/virtualiser/type1/kvm/)
   - [Ansible](https://blog.stephane-robert.info/docs/infra-as-code/gestion-de-configuration/ansible/introduction/)
   - Installer les plugins Vagrant pour Libvirt et Ansible :

     ```bash
     vagrant plugin install vagrant-libvirt
     vagrant plugin install vagrant-hostmanager
     ```

   - Installer les collections Ansible suivantes :

    ```bash
    ansible-galaxy collection install community.general
    ansible-galaxy collection install ansible.posix
    ```

   - Cloner le dÃ©pÃ´t CKASandBox :

    ```bash
    git clone https://github.com/stephrobert/CKASandBox.git
    ```

## ğŸ—ï¸ Ã‰tape 2 - CrÃ©ation des machines virtuelles

1. **Configurez le Vagrantfile** :

  Le fichier `Vagrantfile` contient des variables permettant de personnaliser
  le cluster :

  ```ruby
  base_ip_str = "10.240.0.1"
  number_master = 1 # Nombre de nÅ“uds master : 1 ou 3
  cpu_master = 2
  mem_master = 1792
  number_worker = 1 # Nombre de nÅ“uds worker : 1 ou plus
  cpu_worker = 1
  mem_worker = 1024
  config.vm.box = "generic/ubuntu2204" # Image pour toutes les installations
  kubectl_version = "1.31"
  kube_version = "1.31"
  ```

  Adaptez ces paramÃ¨tres selon les ressources de votre machine et vos besoins.

2. **Lancer le provisionnement des machines** :

  ```bash
  vagrant up
  ```

  Cette commande crÃ©e les machines virtuelles dÃ©finies dans le `Vagrantfile`.

## ğŸ—ï¸ Ã‰tape 3 - AccÃ¨s au contrÃ´leur et initialisation du cluster

1. **Ajouter une entrÃ©e dans le fichier hosts si besoin** :

   Pour faciliter l'accÃ¨s au contrÃ´leur, ajoutez la ligne suivante Ã  votre
   fichier `/etc/hosts` :

   ```plaintext
   10.240.0.10 controller
   ```

2. **Se connecter au master** :

   ```bash
   ssh vagrant@controller
   ```

   Depuis le nÅ“ud master, connectez-vous qur la VM cplane1 :

   ```bash
   ssh cplane1
   ```

3. **Initialiser le cluster Kubernetes** :

   Sur le nÅ“ud master, exÃ©cutez :

   ```bash
   sudo -i
   kubeadm init --pod-network-cidr=192.168.0.0/16 --control-plane-endpoint "10.240.0.10:6443" --upload-certs --cri-socket unix:///run/containerd/containerd.sock
   ```

   Cette commande initialise le plan de contrÃ´le du cluster. Une fois terminÃ©e,
   elle affiche une commande `kubeadm join` Ã  exÃ©cuter sur
   les nÅ“uds worker pour les rejoindre au cluster.

   DÃ©connectez-vous de la VM cplane1 et exÃ©cutez la commande `kubeadm join` sur
   les nÅ“uds worker.

4. **Configurer kubectl sur le contrÃ´leur** :

  Revenue sur la VM controller, exÃ©cutez les commandes suivantes :

   ```bash
   ssh cplane1 sudo cat /etc/kubernetes/admin.conf > ~/.kube/config
   ```

5. **VÃ©rifier l'Ã©tat des nÅ“uds** :

   ```bash
   kubectl get nodes -A
   NAME      STATUS     ROLES           AGE   VERSION
   cplane1   NotReady   control-plane   51s   v1.31.6
   ```

   Les nÅ“uds devraient apparaÃ®tre avec le statut `NotReady`.

## ğŸ—ï¸ Ã‰tape 4 - Installation du rÃ©seau (CNI)

1. **Installer Calico** :

   ```bash
   kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
   ```

2. **VÃ©rifier l'Ã©tat des nÅ“uds** :

   AprÃ¨s quelques minutes, les nÅ“uds devraient passer au statut `Ready` :

   ```bash
   kubectl get nodes -A
   cplane1   Ready    control-plane   113s   v1.31.6
   ```

## ğŸ—ï¸ Ã‰tape 7 - Gestion du cycle de vie des machines

1. **Suspendre les machines** :

   Pour libÃ©rer des ressources sans dÃ©truire les machines :

   ```bash
   vagrant suspend
   ```

2. **Reprendre les machines** :

   Pour reprendre les machines suspendues :

   ```bash
   vagrant resume
   ```

3. **DÃ©truire les machines** :

   Si vous n'avez plus besoin des machines :

   ```bash
   vagrant destroy
   ```

## ğŸš€ Conclusion

Vous avez maintenant un environnement Kubernetes local, flexible et adaptÃ© Ã  la
prÃ©paration de la certification CKA. Cet environnement vous permet de pratiquer
diverses opÃ©rations, de simuler des pannes et de renforcer vos compÃ©tences en
administration Kubernetes. N'hÃ©sitez pas Ã  explorer davantage les
fonctionnalitÃ©s de CKASandBox et Ã  l'adapter Ã  vos besoins spÃ©cifiques.

îˆ€citeîˆ‚turn0search0îˆ